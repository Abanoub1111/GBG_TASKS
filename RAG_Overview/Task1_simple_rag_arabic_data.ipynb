{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNIUAhA8oV/41m/GagSUmy9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abanoub1111/GBG_TASKS/blob/main/RAG_Overview/Task1_simple_rag_arabic_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eLNPquYSkOx",
        "outputId": "b874bd03-6fed-46ad-9b41-5ab4fbce2c31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/23.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/23.8 MB\u001b[0m \u001b[31m191.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/23.8 MB\u001b[0m \u001b[31m238.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m21.9/23.8 MB\u001b[0m \u001b[31m215.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m208.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m208.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q sentence-transformers faiss-cpu langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def normalize_arabic(text):\n",
        "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
        "    text = re.sub(\"ى\", \"ي\", text)\n",
        "    text = re.sub(\"ؤ\", \"و\", text)\n",
        "    text = re.sub(\"ئ\", \"ي\", text)\n",
        "    text = re.sub(\"ة\", \"ه\", text)\n",
        "    text = re.sub(\"[ًٌٍَُِْـ]\", \"\", text)\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "es-_AKc8S9lo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = normalize_arabic(f.read())\n"
      ],
      "metadata": {
        "id": "9len3Y3xS-CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain-text-splitters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X3PmndgTW3q",
        "outputId": "c5750973-f6fc-485a-ff6a-cd28aa2dc5c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-text-splitters\n",
            "  Downloading langchain_text_splitters-1.1.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.13 in /usr/local/lib/python3.12/dist-packages (from langchain-text-splitters) (1.2.13)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (0.7.3)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (26.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (2.12.3)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (9.1.4)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (2.32.4)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain-text-splitters) (2.5.0)\n",
            "Downloading langchain_text_splitters-1.1.1-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: langchain-text-splitters\n",
            "Successfully installed langchain-text-splitters-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=600,\n",
        "    chunk_overlap=100\n",
        ")\n",
        "\n",
        "chunks = splitter.split_text(text)\n",
        "\n",
        "print(\"Number of chunks:\", len(chunks))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhRYv54iTL4J",
        "outputId": "1c7f7da6-c5e3-47fa-c6dc-f778e6cff4fa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of chunks: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "embed_model = SentenceTransformer(\n",
        "    \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "wTT5AIwITMOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_embeddings = embed_model.encode(\n",
        "    chunks,\n",
        "    normalize_embeddings=True,\n",
        "    show_progress_bar=True\n",
        ")"
      ],
      "metadata": {
        "id": "Kdk6D67kTp-m",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "dimension = doc_embeddings.shape[1]\n",
        "index = faiss.IndexFlatIP(dimension)\n",
        "\n",
        "index.add(np.array(doc_embeddings))\n"
      ],
      "metadata": {
        "id": "xF6Y3OryTxeI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(query, k=4):\n",
        "    query_embedding = embed_model.encode(\n",
        "        query,\n",
        "        normalize_embeddings=True\n",
        "    )\n",
        "\n",
        "    scores, indices = index.search(\n",
        "        np.array([query_embedding]),\n",
        "        k\n",
        "    )\n",
        "\n",
        "    return [chunks[i] for i in indices[0]]\n"
      ],
      "metadata": {
        "id": "L4i7HcZPTz-s"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"ماذا كان يسمى البرج الجنوبي سابقا\"\n",
        "\n",
        "results = retrieve(question)\n",
        "\n",
        "for i, chunk in enumerate(results):\n",
        "    print(f\"\\nResult {i+1}:\")\n",
        "    print(chunk)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6aQtG2OT1rU",
        "outputId": "c0bd7369-c224-4785-d458-a84559fdead7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Result 1:\n",
            "ومع دخول المنطقه تحت مظله الحكم العثماني، شهدت القلعه انعطافات تاريخيه ووظيفيه حاده؛ فقد تحولت من مقر للسياده الي ثكنه عسكريه، ثم تلا ذلك تحويل \"البرج الجنوبي\"—الذي كان يعرف سابقا ببرج الرياح لدقه تصميمه في التهويه—الي معتقل سياسي شديد الحراسه خصص للمعارضين من الاعيان والولاه المتمردين. اما الساحات الشماليه الفسيحه، فقد اعيد توظيفها لتصبح \"شوما\" (مخازن) استراتيجيه لتخزين الحبوب والملح والبارود، وهو ما جعلها هدفا متكررا للنيران. ولقد عانت القلعه من نكبات متتاليه، ابرزها \"زلزال القرن السابع عشر\" والحريق الهايل الذي تلاه، مما ادي الي تصدع الاسوار الخارجيه وانهيار الاسقف الخشبيه المزخرفه، لتدخل\n",
            "\n",
            "Result 2:\n",
            "واليوم، تقف \"القلعه البيضاء\" شامخه كايقونه حضاريه ومتحف مفتوح يجتذب الاف الزوار والباحثين سنويا. لقد تم تحويل القاعات القديمه بذكاء هندسي الي صالات عرض متحفيه مكيفه تحفظ المقتنيات وفقا لاعلي المعايير العالميه، كما اعيد تاهيل الفناء الرييسي ليصبح مسرحا مكشوفا ذا خلفيه بانوراميه، يحتضن المهرجانات الموسيقيه والفعاليات الفنيه العالميه. هكذا، لم تعد القلعه مجرد اطلال صامته، بل اصبحت كاينا حيا يروي بصمت جليل قصه الصمود عبر العصور، ورابطا وثيقا يجمع بين عبق الماضي التليد وامال المستقبل المشرق.\n",
            "\n",
            "Result 3:\n",
            "الهندسيه البحته، تميزت القلعه بنظام هيدروليكي سابق لعصره، يعتمد علي شبكه معقده من القنوات الفخاريه لتجميع مياه الامطار وتخزينها في صهاريج بازلتيه ضخمه محفوره في باطن الجبل، مما كفل للحاميه العسكريه الاكتفاء الذاتي من المياه خلال فترات الحصار الخانقه.\n",
            "\n",
            "Result 4:\n",
            "حيث توافد اليها نخبه من المهندسين والمعماريين والحرفيين من اصقاع الاندلس وبلاد الشام ومصر. وقد اثمر هذا التلاقح الثقافي عن تحفه معماريه نادره تجسد \"الطراز المملوكي المتاخر\"، جامعه بين صرامه التحصينات العسكريه—المتمثله في الاسوار السميكه ذات المزاغل الدفاعيه والابراج الاسطوانيه الشاهقه—وبين رقه الفنون الاسلاميه التي تجلت في المشربيات الخشبيه المعشقه، والمقرنصات الحجريه المتدليه، وفسيفساء الخزف التي لا تزال الوانها الفيروزيه تقاوم عاديات الزمن علي الجدران الداخليه للقاعات السلطانيه. ومن الناحيه الهندسيه البحته، تميزت القلعه بنظام هيدروليكي سابق لعصره، يعتمد علي شبكه معقده من القنوات الفخاريه\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7BmRCrL3T3lr"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}